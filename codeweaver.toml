project_path = "/home/knitli/codeweaver-mcp"
project_name = "codeweaver-mcp"
token_limit = 30000
max_file_size = 1048576
max_results = 75
agent = [
    { provider = "anthropic", enabled = true, model = "claude-haiku-4.5", model_settings = {} },
]
data = [
    { provider = "tavily", enabled = true },
    { provider = "duckduckgo", enabled = true },
]

[provider]
embedding = [
    { provider = "voyage", enabled = true, model_settings = { model = "voyage-code-3" } },
]
reranking = [
    { provider = "voyage", enabled = true, model_settings = { model = "voyage:rerank-2.5" } },
]
vector_store = [
    { provider = "qdrant", enabled = true, provider_settings = {} },
]

[[provider.sparse_embedding]]
provider = "sentence-transformers"
enabled = true

[provider.sparse_embedding.model_settings]
model = "opensearch/opensearch-neural-sparse-encoding-doc-v3-gte"

[[provider.agent]]
provider = "anthropic"
enabled = true
model = "claude-sonnet-4-latest"

[provider.agent.model_settings]

[server]
on_duplicate_tools = "warn"
on_duplicate_resources = "warn"
on_duplicate_prompts = "warn"
resource_prefix_format = "path"
middleware = []
tools = []

[logging]
name = "codeweaver"
level = 20
use_rich = false

[logging.rich_options]

[middleware.error_handling]
include_traceback = true
transform_errors = false

[middleware.retry]
max_retries = 5
base_delay = 1.0
max_delay = 60.0
backoff_multiplier = 2.0

[middleware.logging]
log_level = 20
include_payloads = false

[middleware.rate_limiting]
max_requests_per_second = 75
burst_capacity = 150
global_limit = true

[indexer]
forced_includes = [
    "**/.vscode/**",
    "**/.codeweaver/**",
    "**/.github/prompts/**",
    "**/.specify/memory/**",
    "**/.yarn/**",
    "**/.devcontainer/**",
    "**/.cargo/**",
    "**/.mcp.json/**",
    "**/.idea/**",
    "**/.serena/**",
    "**/.roo/commands/**",
    "**/.github/**",
    "**/.ruff.toml/**",
    "**/.stylelintrc.yml/**",
    "**/.stylelintrc.json/**",
    "**/.specify/templates/**",
    "**/.husky/**",
    "**/.continue/**",
    "**/.changeset/**",
    "**/.codex/**",
    "**/.specify/scripts/bash/**",
    "**/.cursor/**",
    "**/.stylelintrc.yaml/**",
    "**/.yarnrc/**",
    "**/.typos.toml/**",
    "**/.github/chatmodes/**",
    "**/.roomodes/**",
    "**/.pre-commit-config.yaml/**",
    "**/.yarnrc.yml/**",
    "**/.mvn/**",
    "**/.specify/**",
    "**/.husky/pre-push/**",
    "**/.husky/pre-commit/**",
    "**/.claude/commands/**",
    "**/.npmrc/**",
    "**/.pre-commit-config.yml/**",
    "**/.roo/**",
    "**/.moon/**",
    "**/.claude/**",
    "**/.stylelintrc/**",
]

[chunker]

[endpoints]
enable_state = true
enable_health = true
enable_stats = true
enable_settings = true
enable_version = true

[uvicorn]

[telemetry]
disable_telemetry = false
tools_before_privacy = false
batch_size = 10
batch_interval_seconds = 60

[default_mcp_config]

[[embedding]]
provider = "sentence-transformers"
enabled = true

[embedding.model_settings]
model = "ibm-granite/granite-embedding-small-english-r2"

[[sparse_embedding]]
provider = "sentence-transformers"
enabled = true

[sparse_embedding.model_settings]
model = "opensearch/openensearch-neural-sparse-encoding-doc-v3-gte"

[[reranking]]
provider = "sentence-transformers"
enabled = true

[reranking.model_settings]
model = "BAAI/bge-reranking-v2-m3"

[vector_store]
provider = "qdrant"
enabled = true

[vector_store.provider_settings]
prefer_grpc = true
url = "http://localhost:6334"
