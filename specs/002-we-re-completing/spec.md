<!--
SPDX-FileCopyrightText: 2025 Knitli Inc.
SPDX-FileContributor: Adam Poulemanos <adam@knit.li>

SPDX-License-Identifier: MIT OR Apache-2.0
-->

# Feature Specification: Vector Storage Provider System

**Feature Branch**: `002-we-re-completing`
**Created**: 2025-10-25
**Status**: Draft
**Input**: User description: "We're completing the vector storage feature for CodeWeaver. There will minimally be at least one Qdrant provider (database-backed) and an in-memory provider. Both need to store and persist embeddings. The vector stores will need to integrate with CodeWeaver's existing types and infrastructure, receiving embeddings generated by one of the existing embedding providers. The providers will need to handle multiple indexes -- sparse and dense, for example. CodeWeaver's default is to generate sparse and dense embeddings for hybrid search. Users should be able to customize provider-specific settings in an object in CodeWeaver settings"

## Execution Flow (main)
```
1. Parse user description from Input
   -> Complete feature description provided
2. Extract key concepts from description
   -> Actors: Users, Vector Store Providers (Qdrant, in-memory)
   -> Actions: Store embeddings, persist embeddings, handle multiple indexes, integrate with existing infrastructure
   -> Data: Embeddings (sparse and dense), indexes, provider settings
   -> Constraints: Must support hybrid search, configurable through settings
3. For each unclear aspect:
   -> RESOLVED: Qdrant is the database provider (already scaffolded)
   -> RESOLVED: In-memory uses qdrant-client's builtin capability with pydantic JSON serialization
   -> RESOLVED: Performance targets flexible for any developer/codebase, server deployment for large scale
4. Fill User Scenarios & Testing section
   -> Clear user flows identified
5. Generate Functional Requirements
   -> Requirements are testable and complete
6. Identify Key Entities
   -> Data entities identified
7. Run Review Checklist
   -> All uncertainties resolved
   -> No implementation details included
8. Return: SUCCESS (spec ready for planning)
```

---

## Quick Guidelines
- Focus on WHAT users need and WHY
- Avoid HOW to implement (no tech stack, APIs, code structure)
- Written for business stakeholders, not developers

---

## Clarifications

### Session 2025-10-25

- Q: When switching between vector store providers (e.g., in-memory → Qdrant) with existing indexed data, what should happen? → A: Warn and block on provider switch; user must manually re-index or revert settings. System detects provider changes and embedding dimension mismatches, providing actionable error message with resolution options. Automatic migration deferred to future enhancement.

- Q: When a user doesn't explicitly configure a collection/index name in settings, what should the system do? → A: Use project name as default collection name (e.g., project "codeweaver-mcp" → collection "codeweaver-mcp").

- Q: How should the system handle embeddings across different git branches? → A: Single shared collection per project with incremental updates. When switching branches, re-index only changed files. Delete embeddings immediately for deleted/renamed/moved files. Filter search results against current filesystem state before returning to user as validation layer to ensure embeddings reflect current working directory.

- Q: Should the Qdrant provider support only local connections, or also remote Qdrant instances? → A: Support both local (default) and remote Qdrant connections. Local runs without authentication. Remote requires URL and optional API key configuration via settings or environment variables. This enables free usage via both local deployment and Qdrant Cloud free tier.

- Q: When sparse embeddings succeed but dense embeddings fail to generate for a code chunk, what should happen? → A: Store chunk with sparse-only embeddings and mark as "incomplete" in metadata. Background process periodically retries generating missing dense embeddings. This ensures search capability is always available (sparse-only searches work) while system works toward complete hybrid search, and supports potential sparse-only indexing configurations.

---

## User Scenarios & Testing

### Primary User Story
As a CodeWeaver user, I want the system to efficiently store and retrieve code embeddings so that I can quickly find relevant code using semantic search. The system should support both dense and sparse embeddings for hybrid search, allowing me to get more accurate and comprehensive results. I should be able to choose between a persistent database storage option for production use and an in-memory option for development or testing scenarios.

### Acceptance Scenarios

1. **Given** embeddings have been generated for my codebase, **When** I initialize CodeWeaver with default settings, **Then** the system stores both dense and sparse embeddings in the configured vector store provider

2. **Given** I have previously indexed my codebase, **When** I restart CodeWeaver, **Then** the system retrieves previously stored embeddings without needing to re-embed files

3. **Given** I perform a semantic code search, **When** the query is processed, **Then** the system searches both sparse and dense indexes and returns hybrid search results ranked by relevance

4. **Given** I want to use in-memory storage for testing, **When** I configure the in-memory provider in settings, **Then** the system stores embeddings in memory and persists them to disk on shutdown

5. **Given** I want to use a database for production, **When** I configure a database provider in settings, **Then** the system stores embeddings persistently in the database with appropriate indexing

8. **Given** I want to use Qdrant Cloud for remote storage, **When** I configure Qdrant URL and API key in settings, **Then** the system connects to the remote Qdrant instance and stores embeddings there

9. **Given** I use Qdrant locally without configuration, **When** I initialize CodeWeaver, **Then** the system connects to Qdrant on localhost without requiring authentication

6. **Given** I update a file in my codebase, **When** the file is re-indexed, **Then** the system updates only the affected embeddings in both sparse and dense indexes

7. **Given** I configure provider-specific settings, **When** the vector store is initialized, **Then** the provider respects my custom configuration (e.g., collection names, index parameters)

### Edge Cases
- **Vector store operation failures**: System logs error and raises provider-specific exception (ConnectionError, StorageError). Client code must handle retries. (Covered by FR-038, FR-039)
- **Corrupted embedding data**: System detects dimension mismatch, logs error, excludes from results. Requires manual file re-indexing. (Covered by FR-043)
- **Provider switching**: System detects provider changes and blocks startup with clear error message. User must either: (1) re-index codebase with new provider, or (2) revert provider setting. Automatic migration deferred to future enhancement. (Covered by FR-042)
- **Partial embedding failure**: When sparse embeddings succeed but dense embeddings fail, system logs error and skips chunk (does not store incomplete embeddings). User must resolve embedding provider issue and manually re-index affected files. Future enhancement: store sparse-only and retry in background.
- **Corrupted persistence file**: Memory provider validates on restore; if invalid, falls back to empty state and logs error with backup location. User must manually repair or delete corrupted file. (Covered by FR-047)
- **Concurrent write operations**: Last-write-wins semantics. Qdrant uses versioning; Memory uses in-memory locks. (Covered by FR-048)
- **Dimension mismatch**: System validates embedding dimensions match collection schema on upsert; blocks operation with clear error if incompatible. (Covered by FR-043)
- **Stale embeddings**: Search results are filtered against current filesystem state before returning to user, ensuring deleted/moved files don't appear in results even if embeddings temporarily persist. (Covered by FR-037)

## Requirements

### Functional Requirements

#### Core Storage Operations
- **FR-001**: System MUST accept embeddings from existing CodeWeaver embedding providers
- **FR-002**: System MUST store both sparse and dense embeddings for each code chunk when both are available
- **FR-003**: System MUST support creating and managing multiple named collections
- **FR-004**: System MUST allow upserting code chunks with their embeddings into the vector store
- **FR-005**: System MUST support searching for similar vectors using a query vector
- **FR-006**: System MUST support hybrid search combining sparse and dense embeddings
- **FR-007**: System MUST allow deletion of embeddings by file path, chunk ID, or chunk name
- **FR-008**: System MUST use project name as default collection name when user does not explicitly configure one

#### Provider Implementation
- **FR-009**: System MUST complete the Qdrant vector store provider implementation (currently scaffolded in codebase)
- **FR-010**: System MUST provide an in-memory vector store provider using qdrant-client's built-in in-memory capability
- **FR-011**: System MUST allow users to select their preferred vector store provider through configuration
- **FR-012**: System MUST follow the existing `VectorStoreProvider` abstract interface pattern established in the codebase
- **FR-013**: System MUST integrate with CodeWeaver's existing type system (CodeChunk, SearchResult, Filter)
- **FR-014**: Qdrant provider MUST support both local connections (localhost, default) and remote connections (via configured URL)
- **FR-015**: Qdrant provider MUST support optional API key authentication for remote connections via settings or environment variables
- **FR-016**: Qdrant provider MUST default to localhost connection when no URL is configured

#### Persistence and Data Management
- **FR-017**: In-memory provider MUST persist embeddings to disk using pydantic-based JSON serialization with configurable storage path
- **FR-018**: In-memory provider MUST restore embeddings from disk on startup using pydantic model validation
- **FR-019**: Qdrant provider MUST persist embeddings automatically without requiring manual save operations
- **FR-020**: System MUST maintain consistency between sparse and dense vectors within collection for each code chunk when both are available. Consistency model: Qdrant provider guarantees atomicity within single upsert operation (both vectors stored together or neither); Memory provider provides eventual consistency with periodic persistence.
- **FR-021**: System MUST handle incremental updates when files are modified without requiring full re-indexing
- **FR-022**: System MUST use single shared collection per project across all git branches
- **FR-023**: System MUST detect and delete embeddings for files that have been deleted, renamed, or moved
- **FR-024**: System MUST track file paths in embedding metadata to enable filesystem validation

#### Configuration and Customization
- **FR-025**: System MUST allow users to configure provider-specific settings through CodeWeaver settings
- **FR-026**: System MUST support provider-specific configuration options (e.g., collection names, connection strings, index parameters)
- **FR-027**: System MUST validate provider settings and provide clear error messages for invalid configurations
- **FR-028**: System MUST allow users to configure index storage paths for file-based providers
- **FR-029**: System MUST support environment variable-based configuration for sensitive values (API keys, credentials)
- **FR-030**: System MUST allow users to configure Qdrant URL for remote connections in settings
- **FR-031**: System MUST allow users to configure Qdrant API key via settings or environment variables for remote authentication

#### Search and Retrieval
- **FR-032**: System MUST return search results with relevance scores
- **FR-033**: System MUST support filtering search results based on metadata (file paths, languages, etc.)
- **FR-034**: System MUST allow configuring the number of results returned from searches
- **FR-035**: System MUST handle queries for both sparse-only, dense-only, and hybrid search modes
- **FR-036**: System MUST return results in a consistent format regardless of the underlying vector store provider
- **FR-037**: System MUST filter search results against current filesystem state before returning to user, excluding results for files that no longer exist at their stored paths

#### Error Handling and Resilience
- **FR-038**: System MUST gracefully handle vector store connection failures with clear error messages and troubleshooting guidance (check URL, API key, network connectivity)
- **FR-039**: System MUST provide clear error messages when storage operations fail
- **FR-040**: System MUST prevent data corruption during write operations with appropriate consistency guarantees for the chosen provider. Memory provider: eventual consistency via periodic disk persistence (configurable interval). Qdrant provider: read-after-write consistency within single collection (write acknowledged only after durable storage).
- **FR-041**: System MUST log all vector store operations for debugging and monitoring
- **FR-042**: System MUST detect vector store provider changes on startup and block initialization if existing embeddings are incompatible, providing actionable error message with resolution options (re-index or revert settings)
- **FR-043**: System MUST validate embedding dimensions match collection schema on upsert and reject incompatible embeddings with clear error message
- **FR-044**: Memory provider MUST validate persistence file integrity during restore using JSON schema validation. If corruption detected, system falls back to empty state initialization and logs error with backup file location. Users must manually repair or delete corrupted persistence file.
- **FR-045**: System MUST handle concurrent write operations to the same chunk using last-write-wins semantics, where the most recent upsert operation determines final chunk state. Qdrant handles this via versioning; Memory provider uses in-memory lock for write serialization.

#### Performance Requirements
- **FR-046**: System MUST support concurrent read operations with performance scaling based on deployment mode (local development vs server deployment)
- **FR-047**: System MUST handle write operations without blocking search queries. Search queries may return results reflecting state before or after concurrent writes (eventual consistency for background indexing workflows). This does not contradict FR-020: individual chunk upserts remain atomic (sparse+dense together), but global index visibility is eventually consistent.
- **FR-048**: System MUST support indexing and searching codebases of any size, with expectation that users deploy as a server for large-scale codebases (10,000+ files or 1M+ embeddings)

### Key Entities

- **VectorStoreProvider**: Abstract interface representing any vector storage backend. Contains configuration, client instance, and operations for search, upsert, and deletion.

- **CodeChunk**: Represents a segment of code with its associated metadata. Contains text content, file path, language, position information, and generated embeddings (both sparse and dense).

- **Embedding**: Numerical vector representation of code. Can be dense (continuous values, e.g., 768-dimensional float vectors) or sparse (mostly zero values, e.g., keyword-based representations). Associated with specific embedding provider and model.

- **Collection**: Named container for embeddings within a vector store (also called "index" in some vector databases; CodeWeaver uses "collection" terminology consistently with Qdrant). Supports specific vector dimensions and distance metrics. May have provider-specific configuration (sharding, replication, etc.).

- **SearchResult**: Result from a vector similarity search. Contains matching CodeChunk, relevance score, and metadata about the search (which collections were used, search mode).

- **Filter**: Query constraints for vector searches. Supports filtering by file path patterns, programming languages, date ranges, and custom metadata fields.

- **ProviderSettings**: Configuration object for vector store providers. Contains provider selection, connection parameters, index settings, and provider-specific options. Integrated into CodeWeaver's unified settings system.

---

## Review & Acceptance Checklist

### Content Quality
- [x] No implementation details (languages, frameworks, APIs)
- [x] Focused on user value and business needs
- [x] Written for non-technical stakeholders
- [x] All mandatory sections completed

### Requirement Completeness
- [x] No [NEEDS CLARIFICATION] markers remain - **All clarifications resolved**
- [x] Requirements are testable and unambiguous
- [x] Success criteria are measurable
- [x] Scope is clearly bounded
- [x] Dependencies and assumptions identified

### Resolved Clarifications
1. **Database Provider Selection**: ✅ Complete Qdrant provider implementation (already scaffolded in codebase)
2. **In-Memory Persistence**: ✅ Use qdrant-client's built-in in-memory capability with pydantic-based JSON serialization to configurable storage path
3. **Performance Requirements**: ✅ Flexible targets supporting any developer/codebase size, with server deployment assumption for large scale (10,000+ files or 1M+ embeddings)
4. **Concurrency Guarantees**: ✅ Support concurrent reads with performance scaling by deployment mode; eventual consistency acceptable for writes
5. **Maximum Scale**: ✅ Support any codebase size with appropriate deployment model (local for small, server for large)

---

## Execution Status

- [x] User description parsed
- [x] Key concepts extracted
- [x] Ambiguities identified and resolved
- [x] User scenarios defined
- [x] Requirements generated and validated
- [x] Entities identified
- [x] Review checklist passed - **READY FOR PLANNING**

---

## Future Enhancements

The following capabilities are deferred to post-MVP releases:

1. **Background Retry for Incomplete Embeddings**: Automatically retry dense embedding generation for chunks that initially failed, allowing sparse-only storage with eventual completion.

2. **Automatic Provider Migration**: Support seamless migration between providers (e.g., Memory → Qdrant) without manual re-indexing.

3. **Multi-Project Collections**: Support multiple CodeWeaver projects sharing single Qdrant instance with isolated collections.

---
